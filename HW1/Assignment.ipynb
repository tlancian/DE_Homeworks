{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LIBRARIES NEEDED ####\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FUNCTIONS ####\n",
    "\n",
    "\n",
    "## Get Influenza's related words\n",
    "\n",
    "def get_outlinks(url):\n",
    "    '''This function takes the out links of a page given in url.\n",
    "        /wiki is the starting tag of wikipedia pages\n",
    "        PMID is the tag for counting the citations in a page (we are not interested about it)'''\n",
    "    \n",
    "    base_wiki_url = \"https://it.wikipedia.org/wiki/\"\n",
    "    \n",
    "    # Request the page\n",
    "    page_response = requests.get(url)\n",
    "    \n",
    "    # Parse the page\n",
    "    soup = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    \n",
    "    #Add out-links\n",
    "    edges = []\n",
    "    one_hop_links = []\n",
    "    \n",
    "    # Get neighbors of seed-url\n",
    "    for link in soup.find_all('a'):\n",
    "        temp = str(link.get('href'))\n",
    "        if temp[0:5] == \"/wiki\" and \"PMID\" not in temp and \":\" not in temp and \"secolo\" not in temp:\n",
    "            try:\n",
    "                int(temp[-4:])\n",
    "            except:\n",
    "                one_hop_links.append(temp[6:])\n",
    "                edges.append(frozenset([\"influenza\", temp[6:]]))\n",
    "    \n",
    "    one_hop_links = list(set(one_hop_links))\n",
    "    \n",
    "    print(one_hop_links)\n",
    "        \n",
    "    for page in one_hop_links[:10]:\n",
    "        \n",
    "        url = base_wiki_url + page\n",
    "        \n",
    "        # Request the page\n",
    "        page_response = requests.get(url)\n",
    "        \n",
    "        # Parse the page\n",
    "        soup = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "        \n",
    "        # Get neighbors of seed-url\n",
    "        for link in soup.find_all('a'):\n",
    "            temp = str(link.get('href'))\n",
    "            if temp[0:5] == \"/wiki\" and \"PMID\" not in temp and \":\" not in temp and \"secolo\" not in temp:\n",
    "                try:\n",
    "                    int(temp[-4:])\n",
    "                except:\n",
    "                    edges.append(frozenset([page, temp[6:]]))\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def get_data(words):\n",
    "    \n",
    "    if len(words) > 10:\n",
    "        return print(\"No man, you can put just 10 words maximum\")\n",
    "\n",
    "    bs_url = \"https://tools.wmflabs.org/pageviews/?project=it.wikipedia.org&platform=all-access&agent=user&range=all-time&pages=\"+\"|\".join(words)\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(bs_url)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "    first_click = driver.find_elements_by_tag_name(\"button\")\n",
    "    first_click[6].click()\n",
    "    \n",
    "    driver.find_element_by_class_name(\"download-csv\").click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Influenza's related words\n",
    "- Get Data and Ground Truth\n",
    "- Build Time Series\n",
    "- Measure Correlation\n",
    "- Model it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Influenza's related words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what we're going to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starting Link\n",
    "seed_url = \"https://it.wikipedia.org/wiki/Influenza\"\n",
    "\n",
    "wiki_links = get_outlinks(seed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [frozenset([4,5]),frozenset([4,5]),frozenset([5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data and Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Flu_data Functions\n",
    "\n",
    "def get_week_number(entire_date):\n",
    "    return entire_date.date().isocalendar()[1]\n",
    "\n",
    "def get_year(entire_date):\n",
    "    return entire_date.year\n",
    "\n",
    "def merge_df(a,b):\n",
    "    return a.append(b)\n",
    "\n",
    "\n",
    "### Influnet Functions\n",
    "\n",
    "def get_year_influnet(date):\n",
    "    return int(date[:4])\n",
    "\n",
    "def get_week_influnet(date):\n",
    "    return int(date[5:])\n",
    "\n",
    "def match_data(year,week):\n",
    "    val = gt[\"Incidence\"].loc[(gt[\"Year\"] == year) & (gt[\"Week\"] == week)]\n",
    "    return float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Useless to run this cell! data are already stored in data folder!!! ####################\n",
    "\n",
    "# choosen manually now\n",
    "related_words = [\"influenza\", \"febbre\", \"vomito\"]\n",
    "\n",
    "#Download data\n",
    "get_data(related_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "flu_data = pd.read_csv(\"data/flu_data.csv\")\n",
    "\n",
    "# Convert date to datetime\n",
    "flu_data[\"Date\"] = pd.to_datetime(flu_data[\"Date\"], yearfirst=True)\n",
    "\n",
    "# Get week number and year\n",
    "flu_data[\"Week\"] = flu_data[\"Date\"].apply(get_week_number)\n",
    "flu_data[\"Year\"] = flu_data[\"Date\"].apply(get_year)\n",
    "\n",
    "# Group by week number and year\n",
    "flu_data = flu_data.groupby([\"Year\", \"Week\"]).sum()\n",
    "flu_data = flu_data.stack()\n",
    "\n",
    "weeks_of_interest = {2015: [[42,53]], 2016: [[1,16], [42,52]], 2017: [[1,17], [42,52]], 2018: [[1,17]]}\n",
    "\n",
    "# Merging Dataframes\n",
    "temp = []\n",
    "for k,v in weeks_of_interest.items():\n",
    "    for elem in v:\n",
    "        temp.append(flu_data.loc[k,list(range(elem[0],elem[1]+1))])\n",
    "        \n",
    "        \n",
    "flu_data = reduce(merge_df, temp).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influnet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the csv files from influnet folder clean the dataframes and return a dataframe containing the ground truth\n",
    "# the gt dataframe has two columns: the week and the incidence value\n",
    "\n",
    "files = glob.glob(\"data/influnet/*\")\n",
    "temp_gt = []\n",
    "for file in files:\n",
    "    print(\"Adding file \" + file + \" ...\")\n",
    "    temp = pd.read_csv(file, header=None)\n",
    "    temp = temp[[0,4]]\n",
    "    temp = temp.drop(temp.index[0:3])\n",
    "    temp = temp.replace(to_replace=\",\", value=\".\", regex=True)\n",
    "    temp[4] = pd.to_numeric(temp[4])\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp.columns=[\"Week\",\"Incidence\"]\n",
    "    temp_gt.append(temp)\n",
    "\n",
    "gt = pd.concat(temp_gt, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[\"Year\"] = gt[\"Week\"].apply(get_year_influnet)\n",
    "gt[\"Week\"] = gt[\"Week\"].apply(get_week_influnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data[\"GT\"] = [\"0\" for _ in range(flu_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data = flu_data.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in flu_data.index.levels[0]:\n",
    "    for week in flu_data.index.levels[1]:\n",
    "        try:\n",
    "            flu_data.loc[year,[week],\"GT\"] = match_data(year,week)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data = flu_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data.GT.plot(secondary_y=True, label=\"Influnet\", figsize=(17,7), legend=True)\n",
    "flu_data.Influenza.plot(label=\"Influenza\", legend=True)\n",
    "flu_data.Febbre.plot(label=\"Febbre\", legend=True)\n",
    "flu_data.Vomito.plot(label=\"Vomito\", legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
